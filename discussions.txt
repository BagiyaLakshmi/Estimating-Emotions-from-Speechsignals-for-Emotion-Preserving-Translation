

----------------------/


-----------------------------------------
Discussion - 1    May 26, 2024
-----------------------------------------
Team members: 
    Cynddia  
    Harini C J 
    Suhasini 
    Bagiya Lakshmi S

Mentor :  Ms. Anushiya Rachel 

1. Choosing the Domain 
    - Speech Signal Processing 

2. Project ideas from mentor: 
    - Multilingual text to speech synthesis or multilingual speech recognition 
    - Methods to automatically evaluate synthesized speech
    - Work on diagnosis of health conditions from speech
work on diagnosis of health conditions from speech


-----------------------------------------
Discussion - 2    May 29, 2024 (Internal)
-----------------------------------------
Team members: 
    Cynddia  
    Harini C J 
    Suhasini 
    Bagiya Lakshmi S

Mentor :  Ms. Anushiya Rachel 

1. To Decide the Project title

2. Project ideas: 
    Suhasini :
        1. Utilizing speech analysis to detect emotions and stress levels
    Bagiya : 
        2. Speech Therapy Assistant: Develop an app that provides interactive speech therapy exercises, giving real-time feedback on pronunciation and speech fluency.
        3. Create a TTS system that can generate speech in different accents and dialects within the same language.
    Cynddia: 
        4. Speech-Based Lie Detection: Detect deception in speech using acoustic and linguistic features, possibly enhanced with visual cues from facial expressions and body language.
        5. Speech-Driven Data Visualization : Build systems that convert spoken queries into dynamic data visualizations, aiding in data analysis and presentation.


-----------------------------------------
Discussion - 3    May 31, 2024 (Internal)
-----------------------------------------
Team members: 
    Cynddia  
    Harini C J 
    Suhasini 
    Bagiya Lakshmi S

Mentor :  Ms. Anushiya Rachel 

1. Decided the Project title
2. Conclusion: 1st Problem Statement 
    Utilizing speech analysis to detect emotions and stress levels
3. Capstone project form submitted.


-----------------------------------------
Discussion - 4   August 04, 2024 (Internal)
-----------------------------------------
Team members: 
    Cynddia  
    Harini C J 
    Suhasini 
    Bagiya Lakshmi S

Mentor :  Ms. Anushiya Rachel 

1. Key Points to discuss with the Mentor 
    * About dataset 
    * Fixing Deadlines 
    * Methodology 
    * Can we implement GenAI
    * About reference research papers 

2. Meeting scheduled with Mentor: August 06, 2024

-----------------------------------------
Discussion - 5   August 06, 2024
-----------------------------------------
Team members: 
    Cynddia  
    Harini C J 
    Suhasini 
    Bagiya Lakshmi S

Mentor :  Ms. Anushiya Rachel 

Key points discussed 

1. IEMOCAP Dataset 
2. Research paper 
    - Inter speech 
    - IEEE audio n speech 
    - computer speech language 
    - speech communication

3. Speech recognition 7th sem 
4. Speech synthesis 8th sem
3. Identify generic emotions 
4. Get the percentage of emotion from a conversational speech

Started studying research papers 

-----------------------------------------
Discussion - 6   August 15, 2024 (Internal)
-----------------------------------------
Team members: 
    Cynddia  
    Harini C J 
    Suhasini 
    Bagiya Lakshmi S

Mentor :  Ms. Anushiya Rachel 

1. Dataset Downloading : https://sail.usc.edu/databases/iemocap/small/
2. Credentials were given 
3. Downloaded Dataset of 12 GB(ZIP File) : 
    IEMOCAP_full_release_withoutVideos.tar.gz

4. Understanding the dataset
5. Dataset g drive : https://drive.google.com/file/d/1-Ruj9hE3obnD66dvqNEjAl0H-sA68YSO/view?usp=drive_link



-----------------------------------------
Discussion - 7   September 02, 2024 (Internal)
-----------------------------------------
Team members: 
    Cynddia  
    Harini C J 
    Suhasini 
    Bagiya Lakshmi S

Mentor :  Ms. Anushiya Rachel 

Workflow 

1. Data Preprocessing 
data cleaning: Remove noise, silence 

2. Feature extraction 
- MFCCs 
- prosdic features: Duration, pause and intonation 

3. Feature selection 
4. Labelling : Manually annotate the audio segments with corresponding emotion or stress labels (e.g., happy, sad, angry, stressed, relaxed).
5. Model selection - SVM, Random Forest, Deep Neural Network
6. Training 
7. Evaluation

8. Check for the total amount of data in hours, amount of data per emotion
9. valence, arousal, and dominance values, which are also indicative of emotions.


-----------------------------------------
Discussion - 8   September 03, 2024 (Zeroth Review)
-----------------------------------------
Team members: 
    Cynddia  
    Harini C J 
    Suhasini 
    Bagiya Lakshmi S

Mentor :  Ms. Anushiya Rachel 

1. Literature review 
2. Presented the ppt with Expected Approach and deadlines 
3. Reference Github: https://github.com/ShaheenPerveen/speech-emotion-recognition-iemocap/tree/master


-----------------------------------------
Discussion - 9   October 06, 2024 (Internal)
-----------------------------------------
Team members: 
    Cynddia  
    Harini C J 
    Suhasini 
    Bagiya Lakshmi S

Mentor :  Ms. Anushiya Rachel 

1. Literature Review 
2. exploring Various Architecture for our Implementation 
3. Project Github: https://github.com/BagiyaLakshmi/emotion-and-stress-recognition
4. Documentation 
5. Dataset Preparation 